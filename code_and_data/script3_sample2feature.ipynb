{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_triples(uni_temps):\n",
    "    triples = [re.findall('(%x<(?P<row>[-]?\\d+),(?P<col>\\d+)>)',a) for a in uni_temps]\n",
    "    for i_i, i in enumerate(triples):\n",
    "        for i_j, j in enumerate(i):\n",
    "            k = list(j)\n",
    "            k[1] = eval(k[1])\n",
    "            k[2] = eval(k[2])\n",
    "            triples[i_i][i_j] = k\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2features(sent, uni_temps, triples, target=False):\n",
    "    features = []\n",
    "    for i_row, row in enumerate(sent):\n",
    "        token_features = []\n",
    "        for i in range(len(uni_temps)):\n",
    "            feature = uni_temps[i]\n",
    "            for to_sub in triples[i]:\n",
    "                try:\n",
    "                    content = sent[i_row + to_sub[1]][to_sub[2]]\n",
    "                except IndexError:\n",
    "                    content = '$'\n",
    "                feature = re.sub(to_sub[0], content, feature)\n",
    "            token_features += [feature]\n",
    "        features += [token_features]\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2feature_ids(sent, uni_temps, triples, laxicon):\n",
    "    features = []\n",
    "    for i_row, row in enumerate(sent):\n",
    "        token_features = []\n",
    "        for i in range(len(uni_temps)):\n",
    "            feature = uni_temps[i]\n",
    "            for to_sub in triples[i]:\n",
    "                try:\n",
    "                    content = sent[i_row + to_sub[1]][to_sub[2]]\n",
    "                except IndexError:\n",
    "                    content = '$'\n",
    "                feature = re.sub(to_sub[0], content, feature)\n",
    "            try:\n",
    "                token_features += [str(laxicon[feature])]\n",
    "            except KeyError:\n",
    "                continue\n",
    "        features += [token_features]\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=codecs.open(\"feature.tpl\",'r','utf-8')\n",
    "temps = f.read().strip().split('\\n')\n",
    "uni_temps = []\n",
    "bi_temps = []\n",
    "for line in temps:\n",
    "    if line == '# Unigram':\n",
    "        a = uni_temps\n",
    "        continue\n",
    "    if line == '# Bigram':\n",
    "        a = bi_temps\n",
    "        continue\n",
    "    if line == '':\n",
    "        continue\n",
    "    a += [line]\n",
    "triples = fetch_triples(uni_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not call this chunk if the features are output.\n",
    "\n",
    "#### Read the Data - for Feature Selecting and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=codecs.open(\"trn.samples\",\"r\",'utf-8')\n",
    "s=f.read()\n",
    "s_chunks=[[r.strip().split('\\t') for r in t.strip().split('\\n')] for t in s.strip().split('\\n\\n')]\n",
    "del s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n"
     ]
    }
   ],
   "source": [
    "feature_dict = {}\n",
    "for i, chunk in enumerate(s_chunks):\n",
    "    if not i % 1000:\n",
    "        print(i)\n",
    "    features = sent2features(chunk, uni_temps, triples)\n",
    "    for r in features:\n",
    "        for rr in r:\n",
    "            try:\n",
    "                feature_dict[rr] += 1\n",
    "            except KeyError:\n",
    "                feature_dict[rr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simplified_features = feature_dict.copy()\n",
    "for r in feature_dict.keys():\n",
    "    if feature_dict[r] < 5:\n",
    "        simplified_features.pop(r)\n",
    "p = 0\n",
    "for r in simplified_features.keys():\n",
    "    simplified_features[r] = p\n",
    "    p += 1\n",
    "f = codecs.open(\"simplified_features.dict\", \"w\", \"utf-8\")\n",
    "f.write(str(simplified_features))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call from here if features have been output\n",
    "\n",
    "#### Read the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open(\"simplified_features.dict\", \"r\", \"utf-8\")\n",
    "simplified_features = eval(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=codecs.open(\"test.samples\",\"r\",'utf-8')\n",
    "s=f.read()\n",
    "s_chunks=[[r.strip().split('\\t') for r in t.strip().split('\\n')] for t in s.strip().split('\\n\\n')]\n",
    "del s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "f = codecs.open(\"test.features\", 'w', 'utf-8')\n",
    "for i, chunk in enumerate(s_chunks):\n",
    "    if not i % 1000:\n",
    "        print(i)\n",
    "    features = sent2feature_ids(chunk, uni_temps, triples, simplified_features)\n",
    "    features = ['\\t'.join(r) for r in features]\n",
    "    features = '\\n'.join(features)\n",
    "    f.write(features)\n",
    "    f.write('\\n\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Forming position-of-predicate and target-label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=codecs.open(\"test.samples\",\"r\",'utf-8')\n",
    "s=f.read()\n",
    "s_chunks=[[r.strip().split('\\t') for r in t.strip().split('\\n')] for t in s.strip().split('\\n\\n')]\n",
    "del s\n",
    "f.close()\n",
    "f=codecs.open(\"labelID.dict\",\"r\",'utf-8')\n",
    "labeldict = eval(f.read())\n",
    "f.close()\n",
    "# f = codecs.open(\"test.labels\", 'w', 'utf-8')\n",
    "f2 = codecs.open(\"test.pos\", 'w', 'utf-8')\n",
    "pos = []\n",
    "for sent in s_chunks:\n",
    "    t = sent[0][5]\n",
    "    if t[0] == '0':\n",
    "        pos += ['0']\n",
    "    else:\n",
    "        pos += [t[1:]]\n",
    "#     for token in sent:\n",
    "#         lab = token[11]\n",
    "#         f.write(str(labeldict[lab])+'\\n')\n",
    "#     f.write('\\n')\n",
    "f.close()\n",
    "f2.write('\\n'.join(pos))\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159089"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simplified_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
