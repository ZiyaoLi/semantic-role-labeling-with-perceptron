{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tree import Tree\n",
    "from tree import MyTree\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recPaths(leaves, id_predicate):\n",
    "    predicate = leaves[id_predicate]\n",
    "    ptr = predicate.parent\n",
    "    predicate_parents = []\n",
    "    while ptr:\n",
    "        predicate_parents += [ptr]\n",
    "        ptr = ptr.parent\n",
    "    features = []\n",
    "    for i in leaves:\n",
    "        s = ''\n",
    "        prev_label = ''\n",
    "        ptr = i.parent\n",
    "        while True:\n",
    "            if ptr in predicate_parents:\n",
    "                common_id = predicate_parents.index(ptr)\n",
    "                break\n",
    "            if not ptr.label == prev_label:\n",
    "                s += (ptr.label + '>')\n",
    "                prev_label = ptr.label\n",
    "            ptr = ptr.parent\n",
    "        s += predicate_parents[common_id].label\n",
    "        prev_label = predicate_parents[common_id].label\n",
    "        for t in range(common_id - 1, -1, -1):\n",
    "            ptr = predicate_parents[t]\n",
    "            if not ptr.label == prev_label:\n",
    "                s += ('<' + ptr.label)\n",
    "                prev_label = ptr.label\n",
    "        features += [s]\n",
    "    return features\n",
    "\n",
    "\n",
    "def predMacroFeature(predicate):\n",
    "    father = predicate.parent\n",
    "    grand = father.parent\n",
    "    macroFeature = grand.label + '='\n",
    "    for uncle in grand.children:\n",
    "        if uncle == father:\n",
    "            macroFeature += '(%s)|' % father.label\n",
    "        else:\n",
    "            macroFeature += '%s|' % uncle.label\n",
    "    return macroFeature.strip('|')\n",
    "\n",
    "\n",
    "def fetch_label(s, current_label):\n",
    "    ts=re.search(u'\\((.*)\\*(.*)\\)', s)\n",
    "    tb=re.search(u'\\((.*)\\*', s)\n",
    "    te=re.search(u'\\*(.*)\\)', s)\n",
    "    if ts is not None:\n",
    "        return 'S-' + ts.group(1), 'O'\n",
    "    if tb is not None:\n",
    "        return 'B-' + tb.group(1), tb.group(1)\n",
    "    if te is not None:\n",
    "        return 'E-' + current_label, 'O'\n",
    "    if current_label == 'O':\n",
    "        return 'O', 'O'\n",
    "    return 'I-' + current_label, current_label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "datastr = 'test'\n",
    "f = codecs.open(datastr + \".textparsed\",\"r\",\"utf-8\")\n",
    "s_tree = f.read().strip().split('\\n')\n",
    "f = codecs.open(datastr + \".mg\",\"r\",'utf-8')\n",
    "s_chunks = [[r.strip().split('\\t') for r in t.strip().split('\\n')] for t in f.read().strip().split('\\n\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trans to trees\n",
    "trees = []\n",
    "for t in s_tree:\n",
    "    tr = Tree.fromstring(t)\n",
    "    trees += [tr]\n",
    "mytrees = []\n",
    "myleaves = []\n",
    "for i, tree in enumerate(trees):\n",
    "    _mytree = MyTree(tree)\n",
    "    _mytree.labelDependencyTree()\n",
    "    _mytree.findDependencyParent()\n",
    "    mytrees += [_mytree]\n",
    "    myleaves += [_mytree.leaves()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "sampleIds = []\n",
    "for i_sent, sent in enumerate(s_chunks):\n",
    "    pos_verbs = []\n",
    "    postag_verbs = []\n",
    "    word_verbs = []\n",
    "    for idx, m in enumerate(sent):\n",
    "        if not m[2] == '-':\n",
    "            pos_verbs += [idx]\n",
    "            postag_verbs += [m[1]]\n",
    "            word_verbs += [m[2]]\n",
    "    n_verbs = len(pos_verbs)\n",
    "    for i_verb in range(n_verbs):\n",
    "        sampleIds += [i_sent]\n",
    "        pos_relv = -pos_verbs[i_verb]\n",
    "        sample_sent = []\n",
    "        current_target = 'O'\n",
    "        macroFeature = predMacroFeature(myleaves[i_sent][pos_verbs[i_verb]])\n",
    "        pathFeatures = recPaths(myleaves[i_sent], pos_verbs[i_verb])\n",
    "        for i_token, s in enumerate(sent):\n",
    "            # basic features\n",
    "            sample_token = s[0:2]\n",
    "            \n",
    "            # verb features\n",
    "            sample_token += [word_verbs[i_verb]]\n",
    "            sample_token += [postag_verbs[i_verb]]\n",
    "            sample_token += [macroFeature]\n",
    "            \n",
    "            # relv position features\n",
    "            sample_token += [str(pos_relv)]\n",
    "            if pos_relv < 0:\n",
    "                sample_token += ['bf']\n",
    "            elif pos_relv > 0:\n",
    "                sample_token += ['af']\n",
    "            else:\n",
    "                sample_token += ['at']\n",
    "            pos_relv += 1\n",
    "            sample_token += [pathFeatures[i_token]]\n",
    "            id_depParent = myleaves[i_sent][i_token].dependencyParent\n",
    "            if id_depParent:\n",
    "                sample_token += [myleaves[i_sent][id_depParent - 1].label]\n",
    "                sample_token += [myleaves[i_sent][id_depParent - 1].parent.label]\n",
    "            else:\n",
    "                sample_token += ['ROOT']\n",
    "                sample_token += ['ROOT']\n",
    "            if id_depParent == pos_verbs[i_verb] + 1:\n",
    "                sample_token += ['isPred']\n",
    "            else:\n",
    "                sample_token += ['notPred']\n",
    "            \n",
    "            # fetch labels - just kill this chunk if no label exists.\n",
    "            return_label, current_target = fetch_label(s[3 + i_verb], current_target)\n",
    "            sample_token += [return_label]\n",
    "            \n",
    "            # add to lists\n",
    "            sample_sent += [sample_token]\n",
    "        samples += [sample_sent]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "f = codecs.open(datastr + '.samples','w','utf-8')\n",
    "for i,sent in enumerate(samples):\n",
    "    if not i % 1000:\n",
    "        print(i)\n",
    "    s_sent = []\n",
    "    for token in sent:\n",
    "        s_sent += ['\\t'.join(token)]\n",
    "    s_sent = '\\n'.join(s_sent)\n",
    "    s_sent += '\\n\\n'\n",
    "    f.write(s_sent)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open(datastr + '.sampleids','w','utf-8')\n",
    "f.write(str(sampleIds))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
